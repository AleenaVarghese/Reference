{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d63bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "import calendar\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0c1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Input file generated---------\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./NeoGrowth_CRIF format_17-04-2023_Output/Account.csv\",sep='|',index_col=False)\n",
    "data = data.rename(columns=lambda x: x.strip())\n",
    "data = data.rename(columns = {'REFERENCE_NO':'LOS-APP-ID'})\n",
    "data['CREDIT-GRANTOR']  = np.where(data['SELF-INDICATOR'] != True,'XXXX', 'Neogrowth') \n",
    "\n",
    "data.to_csv('Input_data.csv',index = False)\n",
    "print(\"----------Input file generated---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662aefb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b363509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LOS-APP-ID'] = data['LOS-APP-ID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec66fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data[['LOS-APP-ID']]\n",
    "test = test.drop_duplicates()\n",
    "x = test.shape[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7e3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_add_months(date_in, n):\n",
    "    #print(date_in, n,str(type(date_in)))\n",
    "    if 'datetime.datetime' not in str(type(date_in)) or 'timestamps.Timestamp' not in str(type(date_in)):\n",
    "        date_in = parser.parse(date_in)\n",
    "    if math.isnan(n) == 1:\n",
    "        date_out = np.nan\n",
    "    else:\n",
    "        n = int(n/3)\n",
    "        date_in = pd.to_datetime(date_in, format=\"%d/%m/%y\",infer_datetime_format=True, errors='ignore')\n",
    "        #adding months to date_in\n",
    "        date_out = date_in + relativedelta(months=n)\n",
    "        date_out = date_out.strftime('%d/%m/%Y')\n",
    "    return date_out\n",
    "\n",
    "def udf_dpd(str_in):\n",
    "    n = 3\n",
    "    split_string = [str(str_in)[i:i+n] for i in range(0,len(str(str_in)),n)]\n",
    "    if split_string == '' or len(split_string) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(len(split_string)):\n",
    "            if split_string[i] == 'DDD':\n",
    "                split_string[i] = '-100'\n",
    "            elif split_string[i] == 'XXX':\n",
    "                split_string[i] = '-200'\n",
    "            else:\n",
    "                split_string[i] = split_string[i]\n",
    "            \n",
    "        #split_string = [ i.rstrip('0') for i in split_string ]\n",
    "        \n",
    "        out = max(split_string)\n",
    "    \n",
    "        return out\n",
    "    \n",
    "def udf_dpd_months(str_in, n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        out = str(str_in)[0:n]\n",
    "        return out\n",
    "    \n",
    "def udf_dpd_30(str_in):\n",
    "    n = 3\n",
    "    out = 0\n",
    "    split_string = [str(str_in)[i:i+n] for i in range(0,len(str(str_in)),n)]\n",
    "    if split_string == '':\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(len(split_string)):\n",
    "            if split_string[i] == 'DDD':\n",
    "                split_string[i] = '-100'\n",
    "            elif split_string[i] == 'XXX':\n",
    "                split_string[i] = '-200'\n",
    "            else:\n",
    "                split_string[i] = split_string[i]\n",
    "        try:\n",
    "            split_string = [ i.replace('nan','0') for i in split_string ]\n",
    "            for i in range(len(split_string)):\n",
    "                if split_string[i] != '':\n",
    "                    if int(split_string[i]) > 30:\n",
    "                        split_string[i] = '1'\n",
    "                    else:\n",
    "                        split_string[i] = '0'\n",
    "                else:\n",
    "                    split_string[i] = '0'\n",
    "                out = out + int(split_string[i])\n",
    "        except:\n",
    "            print(str_in)\n",
    "    \n",
    "        return out\n",
    "        \n",
    "def udf_dpd_bad(str_in):\n",
    "    n = 3\n",
    "    out = 0\n",
    "    split_string = [str(str_in)[i:i+n] for i in range(0,len(str(str_in)),n)]\n",
    "    if split_string == '':\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(len(split_string)):\n",
    "            if split_string[i] == 'DDD':\n",
    "                split_string[i] = '-100'\n",
    "            elif split_string[i] == 'XXX':\n",
    "                split_string[i] = '-200'\n",
    "            else:\n",
    "                split_string[i] = split_string[i]\n",
    "        try:\n",
    "            split_string = [ i.replace('nan','0') for i in split_string ]\n",
    "            for i in range(len(split_string)):\n",
    "                if split_string[i] != '':\n",
    "                    if int(split_string[i]) > 0:\n",
    "                        split_string[i] = '1'\n",
    "                    else:\n",
    "                        split_string[i] = '0'\n",
    "                else:\n",
    "                    split_string[i] = '0'\n",
    "                out = out + int(split_string[i])\n",
    "        except:\n",
    "            print(str_in)\n",
    "    \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d35feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strng = 'S06S06S05S06S06S06S06S06S06S06S06S05S05S05S05S05S05S04S04S04S04S05S05S05S05S05S05S05S05S05S04S04S04S04S04S04'\n",
    "index = strng.index('S06')+1\n",
    "month = int(index/3)\n",
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03a1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE-OFF-AMT - amount can't be collected from customer/ customer unable to pay this amount.\n",
    "data['write_off'] = np.where(data['WRITE-OFF-AMT'] > 500, 1, 0)\n",
    "\n",
    "data['b'] = data['DAS - HIST'].str.find('S06') + 1\n",
    "\n",
    "#Adding data['b'] value with the date-reported month\n",
    "data['DATE-REPORTED1'] = data.apply(lambda x: udf_add_months(x['DATE-REPORTED'], x['b']), \n",
    "                        axis=1)\n",
    "              \n",
    "data['write_off_date1_own'] = np.where((data['b'] == 0)&(data['CREDIT-GRANTOR'] != 'XXXX'), data['CLOSE-DT'], data['DATE-REPORTED'])\n",
    "\n",
    "data['write_off_date1_other'] = np.where((data['b'] == 0)&(data['CREDIT-GRANTOR'] != 'XXXX'), data['CLOSE-DT'], data['DATE-REPORTED'])\n",
    "\n",
    "\n",
    "# data['a'] = data['DAS - HIST'].str.find('S16') + 1\n",
    "# data['DATE-REPORTED2'] = data.apply(lambda x: udf_add_months(x['DATE-REPORTED'], x['a']), \n",
    "#                         axis=1)\n",
    "\n",
    "# data['suit_filed_date_own'] = np.where((data['a'] != 0)&(data['CREDIT-GRANTOR'] != 'XXXX'), data['DATE-REPORTED2'], np.nan)\n",
    "# data['suit_filed_date_other'] = np.where((data['a'] != 0)&(data['CREDIT-GRANTOR'] == 'XXXX'), data['DATE-REPORTED2'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43cf250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '20-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '14-10-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '25-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '21-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '15-10-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2010' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-10-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '14-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '24-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-02-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '24-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '15-09-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-04-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '14-04-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-04-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-02-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-07-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-08-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '14-08-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '17-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-07-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-09-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '18-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-02-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '24-07-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '15-04-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '25-06-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '15-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '20-02-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '13-04-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '18-07-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '16-09-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-09-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '25-11-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '24-09-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-08-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '15-01-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-08-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '16-03-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '21-03-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-07-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-10-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '20-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '20-02-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-04-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-01-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '17-02-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '20-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-05-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '29-02-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-01-2023' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '21-08-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-08-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-03-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '17-02-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '17-07-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-05-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '16-04-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '26-06-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-03-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2010' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '23-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '23-12-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-06-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '17-02-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '21-07-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-11-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '21-10-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-09-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '28-05-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-04-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-02-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '31-01-2013' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-01-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '22-07-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '27-01-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "/Users/aleena.varghese/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1047: UserWarning: Parsing '30-04-2011' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "#Fetching unique loan_ids.\n",
    "summary = data[['LOS-APP-ID']]\n",
    "summary = summary.drop_duplicates()\n",
    "\n",
    "#formating date-reported column\n",
    "data['DATE-REPORTED'] = pd.to_datetime(data['DATE-REPORTED'], format=\"%d/%m/%y\",infer_datetime_format=True, errors='ignore')\n",
    "\n",
    "#get starting year from date-reported column by groupby.\n",
    "df1 = data.groupby('LOS-APP-ID', as_index=False)['DATE-REPORTED'].min()\n",
    "df1['min_year'] = pd.DatetimeIndex(df1['DATE-REPORTED']).year\n",
    "#merge loanid df and grouped date-reported data\n",
    "summary = summary.merge(df1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "#get todays date and find the year gap with date-reported.\n",
    "summary['today_date'] = pd.to_datetime('today').strftime(\"%Y-%m-%d\")\n",
    "summary['CREDIT_HISTORY'] = pd.DatetimeIndex(summary['today_date']).year - pd.DatetimeIndex(summary['DATE-REPORTED']).year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633c533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#written off\n",
    "data['count']=data['DAS - HIST'].str.contains('S06')\n",
    "\n",
    "# Sometimes less amount will be there so need to check amount instaed of 's06'\n",
    "data['WRITE_OFF_OWN'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['WRITE-OFF-AMT'] > 500), 1, 0)\n",
    "data['WRITE_OFF_OTHERS'] = np.where((data['CREDIT-GRANTOR'] == 'XXXX') & (data['WRITE-OFF-AMT'] > 500), 1, 0)\n",
    "\n",
    "#-----------\n",
    "#find the first matching index location of 'S06' from 'DAS - HIST'.if there is no matching then the value will be (-1)+1 = 0\n",
    "data['w'] = data['DAS - HIST'].str.find('S06') + 1\n",
    "\n",
    "#Adding data['b'] value with the date-reported month\n",
    "data['DATE-REPORTED_w'] = data.apply(lambda x: udf_add_months(str(x['DATE-REPORTED']), x['w']), \n",
    "                        axis=1)\n",
    "# The below logic is valied need to check with someone \n",
    "# data['write_off_date1_own'] = np.where((data['w'] == 0)&(data['CREDIT-GRANTOR'] != 'XXXX'), data['CLOSE-DT'], data['DATE-REPORTED'])\n",
    "\n",
    "# data['write_off_date1_other'] = np.where((data['w'] == 0)&(data['CREDIT-GRANTOR'] != 'XXXX'), data['CLOSE-DT'], data['DATE-REPORTED'])\n",
    "\n",
    "\n",
    "data['write_off_date1_own'] = np.where((data['w'] != 0) & (data['CREDIT-GRANTOR'] != 'XXXX'), data['DATE-REPORTED_w'], np.nan)\n",
    "\n",
    "data['write_off_date1_other'] = np.where((data['w'] != 0) & (data['CREDIT-GRANTOR'] == 'XXXX'), data['DATE-REPORTED_w'], np.nan)\n",
    "\n",
    "df5 = data.sort_values('write_off_date1_own').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'write_off_date1_own']]\n",
    "summary = summary.merge(df5, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'write_off_date1_own':'WRITE_OFF_OWN_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df5_other = data.sort_values('write_off_date1_other').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'write_off_date1_other']]\n",
    "summary = summary.merge(df5_other, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'write_off_date1_other':'WRITE_OFF_OTHERS_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df_own1 = data.groupby('LOS-APP-ID', as_index=False)['WRITE_OFF_OWN'].max()\n",
    "summary = summary.merge(df_own1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "df_other1 = data.groupby('LOS-APP-ID', as_index=False)['WRITE_OFF_OTHERS'].max()\n",
    "summary = summary.merge(df_other1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "summary['WRITE_OFF_OWN'] = np.where(summary['WRITE_OFF_OWN'] == 1, 'Y', 'N')\n",
    "summary['WRITE_OFF_OTHERS'] = np.where(summary['WRITE_OFF_OTHERS'] == 1, 'Y', 'N')\n",
    "\n",
    "summary['WRITE_OFF_OWN_OWN_LATEST_REPORTED_DATE'] = np.where(summary['WRITE_OFF_OWN'] == 'Y', summary['WRITE_OFF_OWN_LATEST_REPORTED_DATE'], np.nan)\n",
    "summary['WRITE_OFF_OTHERS_LATEST_REPORTED_DATE'] = np.where(summary['WRITE_OFF_OTHERS'] == 'Y', summary['WRITE_OFF_OTHERS_LATEST_REPORTED_DATE'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f967e789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOS-APP-ID', 'DATE-REPORTED', 'min_year', 'today_date',\n",
       "       'CREDIT_HISTORY', 'WRITE_OFF_OWN_LATEST_REPORTED_DATE',\n",
       "       'WRITE_OFF_OTHERS_LATEST_REPORTED_DATE', 'WRITE_OFF_OWN',\n",
       "       'WRITE_OFF_OTHERS', 'WRITE_OFF_OWN_OWN_LATEST_REPORTED_DATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f67cdaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite filed \n",
    "data['count']=data['DAS - HIST'].str.contains('S16|S23')\n",
    "\n",
    "data['SUIT_FILED_OWN'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['SUIT_FILED_OTHERS'] = np.where((data['CREDIT-GRANTOR'] == 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "#-----------\n",
    "data['s0'] = data['DAS - HIST'].str.find('S16') + 1\n",
    "data['s1'] = data['DAS - HIST'].str.find('S23') + 1\n",
    "data['s'] = np.where(data['s0'] > 0, data['s0'], data['s1'])\n",
    "\n",
    "data[['s','count']]\n",
    "data[data['s'] > 0]\n",
    "#print(data['DATE-REPORTED'].head())\n",
    "data['DATE-REPORTED_s'] = data.apply(lambda x: udf_add_months(str(x['DATE-REPORTED']), x['s']), \n",
    "                        axis=1)\n",
    "# data[data['s'] > 0]\n",
    "data['suit_filed_date_own'] = np.where((data['s'] != 0) & (data['CREDIT-GRANTOR'] != 'XXXX'), data['DATE-REPORTED_s'], np.nan)\n",
    "\n",
    "data['suit_filed_date_other'] = np.where((data['s'] != 0) & (data['CREDIT-GRANTOR'] == 'XXXX'), data['DATE-REPORTED_s'], np.nan)\n",
    "\n",
    "df5 = data.sort_values('suit_filed_date_own').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'suit_filed_date_own']]\n",
    "summary = summary.merge(df5, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'suit_filed_date_own':'SUIT_FILED_OWN_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df5_other = data.sort_values('suit_filed_date_other').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'suit_filed_date_other']]\n",
    "summary = summary.merge(df5_other, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'suit_filed_date_other':'SUIT_FILED_OTHERS_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df_own1 = data.groupby('LOS-APP-ID', as_index=False)['SUIT_FILED_OWN'].max()\n",
    "summary = summary.merge(df_own1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "df_other1 = data.groupby('LOS-APP-ID', as_index=False)['SUIT_FILED_OTHERS'].max()\n",
    "summary = summary.merge(df_other1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "summary['SUIT_FILED_OWN'] = np.where(summary['SUIT_FILED_OWN'] == 1, 'Y', 'N')\n",
    "summary['SUIT_FILED_OTHERS'] = np.where(summary['SUIT_FILED_OTHERS'] == 1, 'Y', 'N')\n",
    "\n",
    "summary['SUIT_FILED_OWN_LATEST_REPORTED_DATE'] = np.where(summary['SUIT_FILED_OWN'] == 'Y', summary['SUIT_FILED_OWN_LATEST_REPORTED_DATE'], np.nan)\n",
    "summary['SUIT_FILED_OTHERS_LATEST_REPORTED_DATE'] = np.where(summary['SUIT_FILED_OTHERS'] == 'Y', summary['SUIT_FILED_OTHERS_LATEST_REPORTED_DATE'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ea86930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2021-01-05\n",
      "1   2023-02-28\n",
      "2   2022-08-31\n",
      "3   2023-03-31\n",
      "4   2023-03-31\n",
      "Name: DATE-REPORTED, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#restructure\n",
    "data['count']=data['DAS - HIST'].str.contains('S18')\n",
    "\n",
    "data['RESTRUCTURED_OWN'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['RESTRUCTURED_OTHERS'] = np.where((data['CREDIT-GRANTOR'] == 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['r'] = data['DAS - HIST'].str.find('S18') + 1\n",
    "print(data['DATE-REPORTED'].head())\n",
    "data['DATE-REPORTED_r'] = data.apply(lambda x: udf_add_months(str(x['DATE-REPORTED']), x['r']), \n",
    "                        axis=1)\n",
    "\n",
    "data['restructured_date_own'] = np.where((data['r'] != 0) & (data['CREDIT-GRANTOR'] != 'XXXX'), data['DATE-REPORTED_r'], np.nan)\n",
    "\n",
    "data['restructured_date_other'] = np.where((data['r'] != 0) & (data['CREDIT-GRANTOR'] == 'XXXX'), data['DATE-REPORTED_r'], np.nan)\n",
    "\n",
    "df5 = data.sort_values('restructured_date_own').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'restructured_date_own']]\n",
    "summary = summary.merge(df5, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'restructured_date_own':'RESTRUCTURED_OWN_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df5_other = data.sort_values('restructured_date_other').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'restructured_date_other']]\n",
    "summary = summary.merge(df5_other, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'restructured_date_other':'RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df_rdo = data.groupby('LOS-APP-ID', as_index=False)['RESTRUCTURED_OWN'].max()\n",
    "summary = summary.merge(df_rdo, on='LOS-APP-ID', how='left')\n",
    "\n",
    "df_rdoo = data.groupby('LOS-APP-ID', as_index=False)['RESTRUCTURED_OTHERS'].max()\n",
    "summary = summary.merge(df_rdoo, on='LOS-APP-ID', how='left')\n",
    "\n",
    "summary['RESTRUCTURED_OWN'] = np.where(summary['RESTRUCTURED_OWN'] == 1, 'Y', 'N')\n",
    "summary['RESTRUCTURED_OTHERS'] = np.where(summary['RESTRUCTURED_OTHERS'] == 1, 'Y', 'N')\n",
    "\n",
    "summary['RESTRUCTURED_OWN_LATEST_REPORTED_DATE'] = np.where(summary['RESTRUCTURED_OWN'] == 'Y', summary['RESTRUCTURED_OWN_LATEST_REPORTED_DATE'], np.nan)\n",
    "summary['RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE'] = np.where(summary['RESTRUCTURED_OTHERS'] == 'Y', summary['RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f821609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDT-RPT-ID</th>\n",
       "      <th>LOS-APP-ID</th>\n",
       "      <th>CANDIDATE - ID</th>\n",
       "      <th>CUSTOMER ID/MBR ID</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>KENDRA</th>\n",
       "      <th>SELF-INDICATOR</th>\n",
       "      <th>MATCH-TYPE</th>\n",
       "      <th>ACC-NUM</th>\n",
       "      <th>CREDIT-GRANTOR</th>\n",
       "      <th>...</th>\n",
       "      <th>s</th>\n",
       "      <th>DATE-REPORTED_s</th>\n",
       "      <th>suit_filed_date_own</th>\n",
       "      <th>suit_filed_date_other</th>\n",
       "      <th>RESTRUCTURED_OWN</th>\n",
       "      <th>RESTRUCTURED_OTHERS</th>\n",
       "      <th>r</th>\n",
       "      <th>DATE-REPORTED_r</th>\n",
       "      <th>restructured_date_own</th>\n",
       "      <th>restructured_date_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NEOG230418CR5117983880502</td>\n",
       "      <td>1199105</td>\n",
       "      <td>161812239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31/03/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31/08/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/08/2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NEOG230418CR5117983880502</td>\n",
       "      <td>1199105</td>\n",
       "      <td>870491746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31/03/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31/08/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/08/2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>NEOG230418CR9217983880502</td>\n",
       "      <td>1202418</td>\n",
       "      <td>6286458672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28/02/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>NEOG230418CR0317983880502</td>\n",
       "      <td>1203696</td>\n",
       "      <td>3555840092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/09/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30/09/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>NEOG230418CR0317983880502</td>\n",
       "      <td>1203696</td>\n",
       "      <td>6212932613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/06/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30/08/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/08/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CREDT-RPT-ID LOS-APP-ID  CANDIDATE - ID  \\\n",
       "62    NEOG230418CR5117983880502    1199105       161812239   \n",
       "69    NEOG230418CR5117983880502    1199105       870491746   \n",
       "164   NEOG230418CR9217983880502    1202418      6286458672   \n",
       "1137  NEOG230418CR0317983880502    1203696      3555840092   \n",
       "1144  NEOG230418CR0317983880502    1203696      6212932613   \n",
       "\n",
       "      CUSTOMER ID/MBR ID  BRANCH  KENDRA  SELF-INDICATOR MATCH-TYPE ACC-NUM  \\\n",
       "62                   NaN     NaN     NaN           False    PRIMARY    XXXX   \n",
       "69                   NaN     NaN     NaN           False    PRIMARY    XXXX   \n",
       "164                  NaN     NaN     NaN           False    PRIMARY    XXXX   \n",
       "1137                 NaN     NaN     NaN           False    PRIMARY    XXXX   \n",
       "1144                 NaN     NaN     NaN           False    PRIMARY    XXXX   \n",
       "\n",
       "     CREDIT-GRANTOR  ...    s DATE-REPORTED_s suit_filed_date_own  \\\n",
       "62             XXXX  ...  0.0      31/03/2023                 NaN   \n",
       "69             XXXX  ...  0.0      31/03/2023                 NaN   \n",
       "164            XXXX  ...  0.0      31/12/2020                 NaN   \n",
       "1137           XXXX  ...  0.0      30/09/2021                 NaN   \n",
       "1144           XXXX  ...  0.0      30/06/2021                 NaN   \n",
       "\n",
       "     suit_filed_date_other RESTRUCTURED_OWN RESTRUCTURED_OTHERS     r  \\\n",
       "62                     NaN                0                   1  88.0   \n",
       "69                     NaN                0                   1  88.0   \n",
       "164                    NaN                0                   1   7.0   \n",
       "1137                   NaN                0                   1   1.0   \n",
       "1144                   NaN                0                   1   7.0   \n",
       "\n",
       "     DATE-REPORTED_r restructured_date_own restructured_date_other  \n",
       "62        31/08/2025                   NaN              31/08/2025  \n",
       "69        31/08/2025                   NaN              31/08/2025  \n",
       "164       28/02/2021                   NaN              28/02/2021  \n",
       "1137      30/09/2021                   NaN              30/09/2021  \n",
       "1144      30/08/2021                   NaN              30/08/2021  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['r']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4672edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     N\n",
       "1     N\n",
       "2     N\n",
       "3     N\n",
       "4     N\n",
       "5     N\n",
       "6     N\n",
       "7     N\n",
       "8     N\n",
       "9     N\n",
       "10    N\n",
       "11    N\n",
       "12    N\n",
       "13    N\n",
       "14    N\n",
       "15    N\n",
       "16    N\n",
       "17    N\n",
       "18    N\n",
       "19    N\n",
       "20    N\n",
       "21    N\n",
       "22    N\n",
       "23    N\n",
       "24    N\n",
       "25    N\n",
       "26    N\n",
       "27    N\n",
       "28    N\n",
       "29    N\n",
       "30    N\n",
       "31    N\n",
       "32    N\n",
       "33    N\n",
       "34    N\n",
       "35    N\n",
       "36    N\n",
       "37    N\n",
       "38    N\n",
       "39    N\n",
       "40    N\n",
       "41    N\n",
       "42    N\n",
       "43    N\n",
       "44    N\n",
       "45    N\n",
       "46    N\n",
       "47    N\n",
       "48    N\n",
       "49    N\n",
       "50    N\n",
       "51    N\n",
       "52    N\n",
       "53    N\n",
       "Name: RESTRUCTURED_OWN, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['RESTRUCTURED_OWN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0eea54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2021-01-05\n",
      "1   2023-02-28\n",
      "2   2022-08-31\n",
      "3   2023-03-31\n",
      "4   2023-03-31\n",
      "Name: DATE-REPORTED, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#*****************************************settled\n",
    "data['count']=data['DAS - HIST'].str.contains('S19')\n",
    "\n",
    "data['SETTLED_OWN'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['SETTLED_OTHERS'] = np.where((data['CREDIT-GRANTOR'] == 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['c'] = data['DAS - HIST'].str.find('S19') + 1\n",
    "print(data['DATE-REPORTED'].head())\n",
    "data['DATE-REPORTED3'] = data.apply(lambda x: udf_add_months(str(x['DATE-REPORTED']), x['c']), \n",
    "                        axis=1)\n",
    "\n",
    "data['settled_date_own'] = np.where((data['c'] != 0) & (data['CREDIT-GRANTOR'] != 'XXXX'), data['DATE-REPORTED3'], np.nan)\n",
    "\n",
    "data['settled_date_other'] = np.where((data['c'] != 0) & (data['CREDIT-GRANTOR'] == 'XXXX'), data['DATE-REPORTED3'], np.nan)\n",
    "\n",
    "df5 = data.sort_values('settled_date_own').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'settled_date_own']]\n",
    "summary = summary.merge(df5, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'settled_date_own':'SETLLED_OWN_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df5_other = data.sort_values('settled_date_other').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'settled_date_other']]\n",
    "summary = summary.merge(df5_other, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'settled_date_other':'SETLLED_OTHERS_LATEST_REPORTED_DATE'})\n",
    "\n",
    "\n",
    "df_so = data.groupby('LOS-APP-ID', as_index=False)['SETTLED_OWN'].max()\n",
    "summary = summary.merge(df_so, on='LOS-APP-ID', how='left')\n",
    "\n",
    "df_soo = data.groupby('LOS-APP-ID', as_index=False)['SETTLED_OTHERS'].max()\n",
    "summary = summary.merge(df_soo, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "\n",
    "summary['SETTLED_OWN'] = np.where(summary['SETTLED_OWN'] == 1, 'Y', 'N')\n",
    "summary['SETTLED_OTHERS'] = np.where(summary['SETTLED_OTHERS'] == 1, 'Y', 'N')\n",
    "\n",
    "summary['SETLLED_OWN_LATEST_REPORTED_DATE'] = np.where(summary['SETTLED_OWN'] == 'Y', summary['SETLLED_OWN_LATEST_REPORTED_DATE'], np.nan)\n",
    "summary['SETLLED_OTHERS_LATEST_REPORTED_DATE'] = np.where(summary['SETTLED_OTHERS'] == 'Y', summary['SETLLED_OTHERS_LATEST_REPORTED_DATE'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e61292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************WILFUL_DEFAULT\n",
    "data['count']=data['DAS - HIST'].str.contains('S22')\n",
    "\n",
    "data['WILFUL_DEFAULT_OWN'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "data['WILFUL_DEFAULT_OTHERS'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') & (data['count'] > 0), 1, 0)\n",
    "\n",
    "\n",
    "data['d'] = data['DAS - HIST'].str.find('S22') + 1\n",
    "data['DATE-REPORTED4'] = data.apply(lambda x: udf_add_months(str(x['DATE-REPORTED']), x['d']), \n",
    "                        axis=1)\n",
    "\n",
    "data['wilfull_default_date_own'] = np.where((data['d'] != 0) & (data['CREDIT-GRANTOR'] != 'XXXX')\n",
    "                                            , data['DATE-REPORTED4'], np.nan)\n",
    "\n",
    "data['wilfull_default_date_other'] = np.where((data['d'] != 0) & (data['CREDIT-GRANTOR'] == 'XXXX')\n",
    "                                            , data['DATE-REPORTED4'], np.nan)\n",
    "\n",
    "\n",
    "df6_1 = data[['LOS-APP-ID', 'WILFUL_DEFAULT_OWN', 'WILFUL_DEFAULT_OTHERS']]\n",
    "df6_1 = df6_1.drop_duplicates()\n",
    "\n",
    "summary = summary.merge(df6_1, on='LOS-APP-ID', how='left')\n",
    "\n",
    "summary['WILFUL_DEFAULT_OWN'] = np.where(summary['WILFUL_DEFAULT_OWN'] == 1, 'Y', 'N')\n",
    "summary['WILFUL_DEFAULT_OTHERS'] = np.where(summary['WILFUL_DEFAULT_OTHERS'] == 1, 'Y', 'N')\n",
    "\n",
    "df6 = data.sort_values('wilfull_default_date_own').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'wilfull_default_date_own']]\n",
    "summary = summary.merge(df6, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'wilfull_default_date_own':'WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE'})\n",
    "\n",
    "df6_other = data.sort_values('wilfull_default_date_other').groupby('LOS-APP-ID').head(1)[['LOS-APP-ID', 'wilfull_default_date_other']]\n",
    "summary = summary.merge(df6_other, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'wilfull_default_date_other':'WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE'})\n",
    "\n",
    "summary['WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE'] = np.where(summary['WILFUL_DEFAULT_OWN'] == 'Y', summary['WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE'], np.nan)\n",
    "summary['WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE'] = np.where(summary['WILFUL_DEFAULT_OTHERS'] == 'Y', summary['WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9252e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1    000\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "Name: dpd_2months, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['max_default_lender'] = data['DPD - HIST'].apply(udf_dpd)\n",
    "data['max_default_lender'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender'], 0)\n",
    "\n",
    "data['max_default_lender'] = data['max_default_lender'].replace('nan', 0)\n",
    "data['max_default_lender'] = data['max_default_lender'].replace('', 0)\n",
    "data['max_default_lender'] = data['max_default_lender'].fillna('0')\n",
    "data['max_default_lender'] = data['max_default_lender'].astype(\"int\")\n",
    "\n",
    "df7 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender'].max()\n",
    "summary = summary.merge(df7, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_other'] = data['DPD - HIST'].apply(udf_dpd)\n",
    "data['max_default_other'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other'], 0)\n",
    "\n",
    "data['max_default_other'] = data['max_default_other'].replace('nan', 0)\n",
    "data['max_default_other'] = data['max_default_other'].replace('', 0)\n",
    "data['max_default_other'] = data['max_default_other'].fillna('0')\n",
    "data['max_default_other'] = data['max_default_other'].astype(\"int\")\n",
    "\n",
    "df8 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other'].max()\n",
    "summary = summary.merge(df8, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'max_default_lender':'MAX_DPD_LENDER', 'max_default_other': 'MAX_DPD_OTHERS'})\n",
    "\n",
    "data['today_date'] = pd.to_datetime('today').strftime(\"%Y/%m/%d\")\n",
    "data['today_date'] = pd.to_datetime(data['today_date'], format=\"%Y/%m/%d\")\n",
    "data['diff_months'] = pd.DatetimeIndex(data['today_date']) - pd.DatetimeIndex(data['DATE-REPORTED'])\n",
    "data['diff_months'] = data['diff_months']/np.timedelta64(1,'M')\n",
    "data['diff_months']=data['diff_months'].astype(int)\n",
    "\n",
    "\n",
    "data['last_two_months'] = np.where(data['diff_months'] < 2, data['diff_months']*3, 0)\n",
    "data['last_three_months'] = np.where(data['diff_months'] < 3, data['diff_months']*3, 0)\n",
    "data['last_six_months'] = np.where(data['diff_months'] < 6, data['diff_months']*3, 0)\n",
    "data['last_12_months'] = np.where(data['diff_months'] < 12, data['diff_months']*3, 0)\n",
    "data['last_24_months'] = np.where(data['diff_months'] < 24, data['diff_months']*3, 0)\n",
    "\n",
    "data['dpd_2months'] = data.apply(lambda x: udf_dpd_months(x['DPD - HIST'], x['last_two_months']), axis=1)\n",
    "data['dpd_3months'] = data.apply(lambda x: udf_dpd_months(x['DPD - HIST'], x['last_three_months']), axis=1)\n",
    "data['dpd_6months'] = data.apply(lambda x: udf_dpd_months(x['DPD - HIST'], x['last_six_months']), axis=1)\n",
    "data['dpd_12months'] = data.apply(lambda x: udf_dpd_months(x['DPD - HIST'], x['last_12_months']), axis=1)\n",
    "data['dpd_24months'] = data.apply(lambda x: udf_dpd_months(x['DPD - HIST'], x['last_24_months']), axis=1)\n",
    "\n",
    "\n",
    "print(data['dpd_2months'].apply(udf_dpd).head())\n",
    "data['max_default_lender_2months'] = data['dpd_2months'].apply(udf_dpd)\n",
    "data['max_default_lender_2months'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender_2months'], 0)\n",
    "\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('nan', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].fillna('0')\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].astype(\"int\")\n",
    "\n",
    "df8 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender_2months'].max()\n",
    "summary = summary.merge(df8, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "\n",
    "data['max_default_other_2months'] = data['dpd_2months'].apply(udf_dpd)\n",
    "data['max_default_other_2months'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other_2months'], 0)\n",
    "\n",
    "data['max_default_other_2months'] = data['max_default_other_2months'].replace('nan', 0)\n",
    "data['max_default_other_2months'] = data['max_default_other_2months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_other_2months'] = data['max_default_other_2months'].fillna('0')\n",
    "data['max_default_other_2months'] = data['max_default_other_2months'].astype(\"int\")\n",
    "\n",
    "df9 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other_2months'].max()\n",
    "summary = summary.merge(df9, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_lender_3months'] = data['dpd_3months'].apply(udf_dpd)\n",
    "data['max_default_lender_3months'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender_3months'], 0)\n",
    "\n",
    "data['max_default_lender_3months'] = data['max_default_lender_3months'].replace('nan', 0)\n",
    "data['max_default_lender_3months'] = data['max_default_lender_3months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_lender_3months'] = data['max_default_lender_3months'].fillna('0')\n",
    "data['max_default_lender_3months'] = data['max_default_lender_3months'].astype(\"int\")\n",
    "\n",
    "df10 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender_3months'].max()\n",
    "summary = summary.merge(df10, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_other_3months'] = data['dpd_3months'].apply(udf_dpd)\n",
    "data['max_default_other_3months'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other_3months'],0)\n",
    "\n",
    "data['max_default_other_3months'] = data['max_default_other_3months'].replace('nan', 0)\n",
    "data['max_default_other_3months'] = data['max_default_other_3months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_other_3months'] = data['max_default_other_3months'].fillna('0')\n",
    "data['max_default_other_3months'] = data['max_default_other_3months'].astype(\"int\")\n",
    "\n",
    "df11 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other_3months'].max()\n",
    "summary = summary.merge(df11, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "data['max_default_lender_6months'] = data['dpd_6months'].apply(udf_dpd)\n",
    "data['max_default_lender_6months'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender_6months'], 0)\n",
    "\n",
    "data['max_default_lender_6months'] = data['max_default_lender_6months'].replace('nan', 0)\n",
    "data['max_default_lender_6months'] = data['max_default_lender_6months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_lender_6months'] = data['max_default_lender_6months'].fillna('0')\n",
    "data['max_default_lender_6months'] = data['max_default_lender_6months'].astype(\"int\")\n",
    "\n",
    "df12 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender_6months'].max()\n",
    "summary = summary.merge(df12, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_other_6months'] = data['dpd_6months'].apply(udf_dpd)\n",
    "data['max_default_other_6months'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other_6months'],0)\n",
    "\n",
    "data['max_default_other_6months'] = data['max_default_other_6months'].replace('nan', 0)\n",
    "data['max_default_other_6months'] = data['max_default_other_6months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_other_6months'] = data['max_default_other_6months'].fillna('0')\n",
    "data['max_default_other_6months'] = data['max_default_other_6months'].astype(\"int\")\n",
    "\n",
    "df13 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other_6months'].max()\n",
    "summary = summary.merge(df13, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "\n",
    "data['max_default_lender_12months'] = data['dpd_12months'].apply(udf_dpd)\n",
    "data['max_default_lender_12months'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender_12months'], 0)\n",
    "\n",
    "data['max_default_lender_12months'] = data['max_default_lender_12months'].replace('nan', 0)\n",
    "data['max_default_lender_12months'] = data['max_default_lender_12months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_lender_12months'] = data['max_default_lender_12months'].fillna('0')\n",
    "data['max_default_lender_12months'] = data['max_default_lender_12months'].astype(\"int\")\n",
    "\n",
    "df14 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender_12months'].max()\n",
    "summary = summary.merge(df14, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_other_12months'] = data['dpd_12months'].apply(udf_dpd)\n",
    "data['max_default_other_12months'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other_12months'],0)\n",
    "\n",
    "data['max_default_other_12months'] = data['max_default_other_12months'].replace('nan', 0)\n",
    "data['max_default_other_12months'] = data['max_default_other_12months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_other_12months'] = data['max_default_other_12months'].fillna('0')\n",
    "data['max_default_other_12months'] = data['max_default_other_12months'].astype(\"int\")\n",
    "\n",
    "df15 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other_12months'].max()\n",
    "summary = summary.merge(df15, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "data['max_default_lender_24months'] = data['dpd_24months'].apply(udf_dpd)\n",
    "data['max_default_lender_24months'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['max_default_lender_24months'], 0)\n",
    "\n",
    "data['max_default_lender_24months'] = data['max_default_lender_24months'].replace('nan', 0)\n",
    "data['max_default_lender_24months'] = data['max_default_lender_24months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_lender_24months'] = data['max_default_lender_24months'].fillna('0')\n",
    "data['max_default_lender_24months'] = data['max_default_lender_24months'].astype(\"int\")\n",
    "\n",
    "df16 = data.groupby('LOS-APP-ID', as_index=False)['max_default_lender_24months'].max()\n",
    "summary = summary.merge(df16, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['max_default_other_24months'] = data['dpd_24months'].apply(udf_dpd)\n",
    "data['max_default_other_24months'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['max_default_other_24months'], 0)\n",
    "\n",
    "data['max_default_other_24months'] = data['max_default_other_24months'].replace('nan', 0)\n",
    "data['max_default_other_24months'] = data['max_default_other_24months'].replace('', 0)\n",
    "data['max_default_lender_2months'] = data['max_default_lender_2months'].replace('.', '')\n",
    "data['max_default_other_24months'] = data['max_default_other_24months'].fillna('0')\n",
    "data['max_default_other_24months'] = data['max_default_other_24months'].astype(\"int\")\n",
    "\n",
    "df17 = data.groupby('LOS-APP-ID', as_index=False)['max_default_other_24months'].max()\n",
    "summary = summary.merge(df17, on='LOS-APP-ID', how='left')\n",
    "\n",
    "summary = summary.rename(columns = {'max_default_lender_2months':'MAX_DPD_LENDER_2months', \n",
    "                                    'max_default_other_2months': 'MAX_DPD_OTHERS_2months',\n",
    "                                   'max_default_lender_3months':'MAX_DPD_LENDER_3months', \n",
    "                                    'max_default_other_3months': 'MAX_DPD_OTHERS_3months',\n",
    "                                   'max_default_lender_6months':'MAX_DPD_LENDER_6months', \n",
    "                                    'max_default_other_6months': 'MAX_DPD_OTHERS_6months',\n",
    "                                   'max_default_lender_12months':'MAX_DPD_LENDER_12months', \n",
    "                                    'max_default_other_12months': 'MAX_DPD_OTHERS_12months',\n",
    "                                   'max_default_lender_24months':'MAX_DPD_LENDER_24months', \n",
    "                                    'max_default_other_24months': 'MAX_DPD_OTHERS_24months'})\n",
    "\n",
    "data['max_dpd_all'] = data['DPD - HIST'].apply(udf_dpd)\n",
    "\n",
    "data['max_dpd_all'] = data['max_dpd_all'].replace('nan', 0)\n",
    "data['max_dpd_all'] = data['max_dpd_all'].replace('', 0)\n",
    "data['max_dpd_all'] = data['max_dpd_all'].fillna('0')\n",
    "data['max_dpd_all'] = data['max_dpd_all'].astype(\"int\")\n",
    "\n",
    "df18 = data.groupby('LOS-APP-ID', as_index=False)['max_dpd_all'].max()\n",
    "summary = summary.merge(df18, on='LOS-APP-ID', how='left')\n",
    "\n",
    "\n",
    "status_to_temp_dict = { 'Sold/Purchased':1, 'Current Account': 2, 'Active': 2, 'Delinquent': 3, 'Restructured': 4,\n",
    "                      'Settled': 5, 'Written Off': 6, 'Suit Filed': 7, 'WILFUL DEFAULT': 7, 'Closed Account': 0,\n",
    "                      'Closed': 0, 'SUIT FILED (WILFUL DEFAULT)' : 7, 'Cancelled': 0, 'Loan Declined': 8,'Loan Approved - Not yet disbursed':2,\n",
    "                      'Loan Submitted':2, 'Restructured  and  Closed': 4,'Post Write Off Closed':6,'Post Write Off Settled':6}\n",
    "\n",
    "temp_to_status_dict = { 1:'Sold/Purchased', 2: 'Current Account',3: 'Delinquent', 4:'Restructured',\n",
    "                      5:'Settled', 6:'Written Off', 7:'Suit Filed', 0:'Closed Account', 8 : 'Loan Declined'}\n",
    "\n",
    "\n",
    "data['dpd_status_numbers_own'] = data['ACCOUNT-STATUS']#.apply(udf_status_to_temp)\n",
    "data['dpd_status_numbers_others'] = data['ACCOUNT-STATUS']\n",
    "data = data.replace({\"dpd_status_numbers_own\": status_to_temp_dict})\n",
    "data = data.replace({\"dpd_status_numbers_others\": status_to_temp_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "265cf615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "data['dpd_status_numbers_own'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['dpd_status_numbers_own'], -99)\n",
    "#data.to_csv('Arohan_data.csv',index = False)\n",
    "print(data['dpd_status_numbers_own'].max())\n",
    "df19 = data.groupby('LOS-APP-ID', as_index=False)['dpd_status_numbers_own'].max()\n",
    "summary = summary.merge(df19, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'dpd_status_numbers_own':'DPD_STATUS_OWN'})\n",
    "\n",
    "data['dpd_status_numbers_others'] = np.where(data['CREDIT-GRANTOR'] == 'XXXX', data['dpd_status_numbers_others'], -99)\n",
    "df20 = data.groupby('LOS-APP-ID', as_index=False)['dpd_status_numbers_others'].max()\n",
    "summary = summary.merge(df20, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'dpd_status_numbers_others':'DPD_STATUS_OTHERS'})\n",
    "\n",
    "summary = summary.replace({\"DPD_STATUS_OWN\": temp_to_status_dict})\n",
    "summary = summary.replace({\"DPD_STATUS_OTHERS\": temp_to_status_dict})\n",
    "\n",
    "summary['DPD_STATUS_OWN'] = np.where(summary['DPD_STATUS_OWN'] == -99, np.nan, summary['DPD_STATUS_OWN'])\n",
    "summary['DPD_STATUS_OTHERS'] = np.where(summary['DPD_STATUS_OTHERS'] == -99, np.nan, summary['DPD_STATUS_OTHERS'])\n",
    "\n",
    "data['COUNT_30DPD_OWN'] = data['DPD - HIST'].apply(udf_dpd_30)\n",
    "data['COUNT_30DPD_OWN'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['COUNT_30DPD_OWN'], 0)\n",
    "\n",
    "df22 = data.groupby('LOS-APP-ID', as_index=False)['COUNT_30DPD_OWN'].sum()\n",
    "summary = summary.merge(df22, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['bad'] = data['DPD - HIST'].apply(udf_dpd_bad)\n",
    "data['bad'] = np.where(data['CREDIT-GRANTOR'] != 'XXXX', data['bad'], 0)\n",
    "\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].astype(\"string\")\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].str.replace(',','')\n",
    "\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].replace('nan', 0)\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].replace('', 0)\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].fillna('0')\n",
    "data['CURRENT-BAL'] = data['CURRENT-BAL'].astype(\"int\")\n",
    "\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].astype(\"string\")\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].str.replace(',','')\n",
    "\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].replace('nan', 0)\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].replace('', 0)\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].fillna('0')\n",
    "data['OVERDUE-AMT'] = data['OVERDUE-AMT'].astype(\"int\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6640da89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOS-APP-ID</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>Count</th>\n",
       "      <th>current_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1166440</td>\n",
       "      <td>Active</td>\n",
       "      <td>15</td>\n",
       "      <td>22271352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1166440</td>\n",
       "      <td>Closed</td>\n",
       "      <td>5</td>\n",
       "      <td>-685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1172480</td>\n",
       "      <td>Active</td>\n",
       "      <td>19</td>\n",
       "      <td>16955733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172480</td>\n",
       "      <td>Closed</td>\n",
       "      <td>3</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172801</td>\n",
       "      <td>Active</td>\n",
       "      <td>19</td>\n",
       "      <td>49092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1209388</td>\n",
       "      <td>Active</td>\n",
       "      <td>24</td>\n",
       "      <td>5947760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1209388</td>\n",
       "      <td>Closed</td>\n",
       "      <td>40</td>\n",
       "      <td>20103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1209388</td>\n",
       "      <td>Delinquent</td>\n",
       "      <td>1</td>\n",
       "      <td>52229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1209418</td>\n",
       "      <td>Active</td>\n",
       "      <td>34</td>\n",
       "      <td>4488865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1209418</td>\n",
       "      <td>Closed</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LOS-APP-ID ACCOUNT-STATUS  Count  current_bal\n",
       "0      1166440         Active     15     22271352\n",
       "1      1166440         Closed      5         -685\n",
       "2      1172480         Active     19     16955733\n",
       "3      1172480         Closed      3          588\n",
       "4      1172801         Active     19     49092212\n",
       "..         ...            ...    ...          ...\n",
       "134    1209388         Active     24      5947760\n",
       "135    1209388         Closed     40        20103\n",
       "136    1209388     Delinquent      1        52229\n",
       "137    1209418         Active     34      4488865\n",
       "138    1209418         Closed     19            0\n",
       "\n",
       "[139 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = (data.groupby(['LOS-APP-ID', 'ACCOUNT-STATUS'])['CURRENT-BAL']\n",
    "         .agg([('Count','size'), ('current_bal','sum')])\n",
    "         .reset_index())\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26617bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOS-APP-ID</th>\n",
       "      <th>ACCOUNT-STATUS</th>\n",
       "      <th>Count</th>\n",
       "      <th>current_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LOS-APP-ID, ACCOUNT-STATUS, Count, current_bal]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = ['Closed', 'Settled', 'Cancelled', 'Written Of']\n",
    "df22 = df21.loc[~df21['ACCOUNT-STATUS'].isin(options)] \n",
    "df22[df22['LOS-APP-ID']=='ZL1315187776']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14d423db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df23 = df22.groupby('LOS-APP-ID', as_index=False)['current_bal'].sum()\n",
    "summary = summary.merge(df23, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'current_bal':'POS'})\n",
    "\n",
    "df24 = df22.groupby('LOS-APP-ID', as_index=False)['Count'].sum()\n",
    "summary = summary.merge(df24, on='LOS-APP-ID', how='left')\n",
    "summary = summary.rename(columns = {'Count':'NO_OF_ACTIVE_LOANS'})\n",
    "\n",
    "data['RESTRUCTURE_OWN_FLAG'] = np.where((data['CREDIT-GRANTOR'] != 'XXXX') \n",
    "                                        & (data['ACCOUNT-STATUS'] == 'Restructured'), 1, 0)\n",
    "data['NO_OF_IRREGULAR_LOANS'] = np.where(data['bad']>0,1,0)\n",
    "\n",
    "df25 = data.groupby('LOS-APP-ID', as_index=False)['RESTRUCTURE_OWN_FLAG'].sum()\n",
    "summary = summary.merge(df25, on='LOS-APP-ID', how='left')\n",
    "\n",
    "df26 = data.groupby('LOS-APP-ID', as_index=False)['NO_OF_IRREGULAR_LOANS'].sum()\n",
    "summary = summary.merge(df26, on='LOS-APP-ID', how='left')\n",
    "\n",
    "data['NPA'] = np.where(data['ACCOUNT-STATUS'] != 'Closed',np.where(data['max_dpd_all'] >= 90, data['OVERDUE-AMT'], np.nan), np.nan)\n",
    "\n",
    "df26 = data.groupby('LOS-APP-ID', as_index=False)['NPA'].sum()\n",
    "summary = summary.merge(df26, on='LOS-APP-ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f57700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOS-APP-ID', 'DATE-REPORTED', 'min_year', 'today_date',\n",
       "       'CREDIT_HISTORY', 'WRITE_OFF_OWN_LATEST_REPORTED_DATE',\n",
       "       'WRITE_OFF_OTHERS_LATEST_REPORTED_DATE', 'WRITE_OFF_OWN',\n",
       "       'WRITE_OFF_OTHERS', 'WRITE_OFF_OWN_OWN_LATEST_REPORTED_DATE',\n",
       "       'SUIT_FILED_OWN_LATEST_REPORTED_DATE',\n",
       "       'SUIT_FILED_OTHERS_LATEST_REPORTED_DATE', 'SUIT_FILED_OWN',\n",
       "       'SUIT_FILED_OTHERS', 'RESTRUCTURED_OWN_LATEST_REPORTED_DATE',\n",
       "       'RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE', 'RESTRUCTURED_OWN',\n",
       "       'RESTRUCTURED_OTHERS', 'SETLLED_OWN_LATEST_REPORTED_DATE',\n",
       "       'SETLLED_OTHERS_LATEST_REPORTED_DATE', 'SETTLED_OWN', 'SETTLED_OTHERS',\n",
       "       'WILFUL_DEFAULT_OWN', 'WILFUL_DEFAULT_OTHERS',\n",
       "       'WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE',\n",
       "       'WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE', 'MAX_DPD_LENDER',\n",
       "       'MAX_DPD_OTHERS', 'MAX_DPD_LENDER_2months', 'MAX_DPD_OTHERS_2months',\n",
       "       'MAX_DPD_LENDER_3months', 'MAX_DPD_OTHERS_3months',\n",
       "       'MAX_DPD_LENDER_6months', 'MAX_DPD_OTHERS_6months',\n",
       "       'MAX_DPD_LENDER_12months', 'MAX_DPD_OTHERS_12months',\n",
       "       'MAX_DPD_LENDER_24months', 'MAX_DPD_OTHERS_24months', 'max_dpd_all',\n",
       "       'DPD_STATUS_OWN', 'DPD_STATUS_OTHERS', 'COUNT_30DPD_OWN', 'POS',\n",
       "       'NO_OF_ACTIVE_LOANS', 'RESTRUCTURE_OWN_FLAG', 'NO_OF_IRREGULAR_LOANS',\n",
       "       'NPA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "419bf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#adding history count : # of loans the borrower borrowed irrespective of Active or Inactive/repaid\n",
    "hist_df = data.groupby('LOS-APP-ID', as_index=False).size()\n",
    "hist_df = hist_df.rename(columns = {'size':'Record Count'})\n",
    "summary = summary.merge(hist_df, on = 'LOS-APP-ID', how = 'left')#adding history count\n",
    "\n",
    "#Adding Cibil score into Summary data\n",
    "inp_summary = pd.read_csv(\"./NeoGrowth_CRIF format_17-04-2023_Output/Summary.csv\",sep='|',index_col=False)\n",
    "inp_summary = inp_summary.rename(columns=lambda x: x.strip())\n",
    "inp_summary['LOS-APP-ID'] = inp_summary['LOS-APP-ID'].astype('str')\n",
    "inp_summary.to_csv('Summary.csv',index = False)\n",
    "summary = summary.merge(inp_summary, how ='left', on='LOS-APP-ID')\n",
    "summary = summary.rename(columns={'PERFORM_CNS SCORE':'CIBIL_SCORE'})\n",
    "\n",
    "# NPA Status column add \n",
    "summary['NPA-STATUS']  = np.where(summary['NPA'] > 0,'Yes', 'No') \n",
    "\n",
    "summary = summary[['LOS-APP-ID', 'CREDIT_HISTORY', \n",
    "       'WRITE_OFF_OWN', 'WRITE_OFF_OTHERS', 'WRITE_OFF_OWN_LATEST_REPORTED_DATE', 'WRITE_OFF_OTHERS_LATEST_REPORTED_DATE',\n",
    "       'SUIT_FILED_OWN', 'SUIT_FILED_OTHERS', 'SUIT_FILED_OWN_LATEST_REPORTED_DATE','SUIT_FILED_OTHERS_LATEST_REPORTED_DATE',\n",
    "       'SETTLED_OWN', 'SETTLED_OTHERS', 'SETLLED_OWN_LATEST_REPORTED_DATE', 'SETLLED_OTHERS_LATEST_REPORTED_DATE', \n",
    "       'WILFUL_DEFAULT_OWN', 'WILFUL_DEFAULT_OTHERS', 'WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE', 'WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE', 'MAX_DPD_LENDER',\n",
    "       'RESTRUCTURED_OWN','RESTRUCTURED_OTHERS','RESTRUCTURED_OWN_LATEST_REPORTED_DATE','RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE',        'MAX_DPD_OTHERS', 'MAX_DPD_LENDER_2months', 'MAX_DPD_OTHERS_2months',\n",
    "       'MAX_DPD_LENDER_3months', 'MAX_DPD_OTHERS_3months',\n",
    "       'MAX_DPD_LENDER_6months', 'MAX_DPD_OTHERS_6months',\n",
    "       'MAX_DPD_LENDER_12months', 'MAX_DPD_OTHERS_12months',\n",
    "       'MAX_DPD_LENDER_24months', 'MAX_DPD_OTHERS_24months', 'max_dpd_all',\n",
    "       'DPD_STATUS_OWN', 'DPD_STATUS_OTHERS', 'COUNT_30DPD_OWN', 'POS',\n",
    "       'NO_OF_ACTIVE_LOANS', 'NO_OF_IRREGULAR_LOANS', 'RESTRUCTURE_OWN_FLAG', 'NPA','NPA-STATUS','Record Count','CIBIL_SCORE']]\n",
    "\n",
    "summary.to_excel(\"./NeoGrowth_CRIF_Final.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "679d2267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9df4688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOS-APP-ID', 'CREDIT_HISTORY', 'WRITE_OFF_OWN', 'WRITE_OFF_OTHERS',\n",
       "       'WRITE_OFF_OWN_LATEST_REPORTED_DATE',\n",
       "       'WRITE_OFF_OTHERS_LATEST_REPORTED_DATE', 'SUIT_FILED_OWN',\n",
       "       'SUIT_FILED_OTHERS', 'SUIT_FILED_OWN_LATEST_REPORTED_DATE',\n",
       "       'SUIT_FILED_OTHERS_LATEST_REPORTED_DATE', 'SETTLED_OWN',\n",
       "       'SETTLED_OTHERS', 'SETLLED_OWN_LATEST_REPORTED_DATE',\n",
       "       'SETLLED_OTHERS_LATEST_REPORTED_DATE', 'WILFUL_DEFAULT_OWN',\n",
       "       'WILFUL_DEFAULT_OTHERS', 'WILFULL_DEFAULT_OWN_LATEST_REPORTED_DATE',\n",
       "       'WILFULL_DEFAULT_OTHERS_LATEST_REPORTED_DATE', 'MAX_DPD_LENDER',\n",
       "       'RESTRUCTURED_OWN', 'RESTRUCTURED_OTHERS',\n",
       "       'RESTRUCTURED_OWN_LATEST_REPORTED_DATE',\n",
       "       'RESTRUCTURED_OTHERS_LATEST_REPORTED_DATE', 'MAX_DPD_OTHERS',\n",
       "       'MAX_DPD_LENDER_2months', 'MAX_DPD_OTHERS_2months',\n",
       "       'MAX_DPD_LENDER_3months', 'MAX_DPD_OTHERS_3months',\n",
       "       'MAX_DPD_LENDER_6months', 'MAX_DPD_OTHERS_6months',\n",
       "       'MAX_DPD_LENDER_12months', 'MAX_DPD_OTHERS_12months',\n",
       "       'MAX_DPD_LENDER_24months', 'MAX_DPD_OTHERS_24months', 'max_dpd_all',\n",
       "       'DPD_STATUS_OWN', 'DPD_STATUS_OTHERS', 'COUNT_30DPD_OWN', 'POS',\n",
       "       'NO_OF_ACTIVE_LOANS', 'NO_OF_IRREGULAR_LOANS', 'RESTRUCTURE_OWN_FLAG',\n",
       "       'NPA', 'NPA-STATUS', 'Record Count', 'CIBIL_SCORE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary = summary.drop(['CIBIL_SCORE'], axis=1)\n",
    "summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55471c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching!\n"
     ]
    }
   ],
   "source": [
    "test1 = summary[['LOS-APP-ID']]\n",
    "y = test1.shape[0]\n",
    "if x == y :\n",
    "    print(\"matching!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f39c1c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 54)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832672f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
